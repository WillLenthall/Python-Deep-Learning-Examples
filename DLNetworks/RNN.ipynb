{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aaa34d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = 300\n",
    "max_words = 10000\n",
    "embedding_dim = 100\n",
    "no_reviews = 25492\n",
    "training_samples = 10000\n",
    "validation_samples = 5000\n",
    "test_samples = 5492"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b198b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Review  Rating\n",
      "0      nice hotel expensive parking got good deal sta...       4\n",
      "1      ok nothing special charge diamond member hilto...       2\n",
      "2      nice rooms not 4* experience hotel monaco seat...       3\n",
      "3      unique, great stay, wonderful time hotel monac...       5\n",
      "4      great stay great stay, went seahawk game aweso...       5\n",
      "...                                                  ...     ...\n",
      "20486  best kept secret 3rd time staying charm, not 5...       5\n",
      "20487  great location price view hotel great quick pl...       4\n",
      "20488  ok just looks nice modern outside, desk staff ...       2\n",
      "20489  hotel theft ruined vacation hotel opened sept ...       1\n",
      "20490  people talking, ca n't believe excellent ratin...       2\n",
      "\n",
      "[20491 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"tripadvisor_hotel_reviews.csv/tripadvisor_hotel_reviews.csv\")\n",
    "print (data)\n",
    "\n",
    "reviews = data.Review\n",
    "ratings = data.Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1673995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (ratings)\n",
    "#print (reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d204aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52211 unique tokens\n",
      "Line 1:  ok nothing special charge diamond member hilton decided chain shot 20th anniversary seattle, start booked suite paid extra website description not, suite bedroom bathroom standard hotel room, took printed reservation desk showed said things like tv couch ect desk clerk told oh mixed suites description kimpton website sorry free breakfast, got kidding, embassy suits sitting room bathroom bedroom unlike kimpton calls suite, 5 day stay offer correct false advertising, send kimpton preferred guest website email asking failure provide suite advertised website reservation description furnished hard copy reservation printout website desk manager duty did not reply solution, send email trip guest survey did not follow email mail, guess tell concerned guest.the staff ranged indifferent not helpful, asked desk good breakfast spots neighborhood hood told no hotels, gee best breakfast spots seattle 1/2 block away convenient hotel does not know exist, arrived late night 11 pm inside run bellman busy chating cell phone help bags.prior arrival emailed hotel inform 20th anniversary half really picky wanted make sure good, got nice email saying like deliver bottle champagne chocolate covered strawberries room arrival celebrate, told needed foam pillows, arrival no champagne strawberries no foam pillows great room view alley high rise building good not better housekeeping staff cleaner room property, impressed left morning shopping room got short trips 2 hours, beds comfortable.not good ac-heat control 4 x 4 inch screen bring green shine directly eyes night, light sensitive tape controls.this not 4 start hotel clean business hotel super high rates, better chain hotels seattle,  \n",
      "\n",
      "Coded:  [148, 145, 279, 340, 1653, 897, 508, 370, 991, 3104, 2590, 908, 536, 386, 71, 178, 231, 205, 399, 3267, 3, 178, 438, 46, 276, 1, 2, 100, 3105, 364, 56, 1063, 130, 141, 24, 188, 1978, 4039, 56, 1248, 121, 764, 1103, 533, 3267, 3675, 399, 1279, 62, 21, 36, 4493, 2109, 3317, 634, 2, 46, 438, 1427, 3675, 1104, 178, 41, 20, 8, 400, 1842, 4494, 5494, 1376, 3675, 1450, 411, 399, 988, 894, 786, 178, 1788, 399, 364, 3267, 1131, 208, 3505, 364, 7114, 399, 56, 337, 1715, 9, 3, 3994, 4495, 1376, 988, 48, 411, 7319, 9, 3, 2260, 988, 1692, 625, 424, 1162, 411, 28, 7, 4634, 3374, 3, 40, 137, 56, 6, 21, 1412, 825, 121, 13, 63, 39, 21, 1412, 536, 91, 30, 348, 67, 302, 1, 229, 3, 129, 4147, 108, 246, 17, 451, 703, 577, 405, 1898, 327, 2409, 440, 238, 458, 871, 322, 2355, 1, 4560, 2590, 908, 369, 27, 1136, 164, 69, 119, 6, 36, 11, 988, 803, 24, 2914, 499, 773, 994, 1256, 3752, 2, 322, 2047, 121, 274, 5495, 565, 322, 13, 773, 3752, 13, 5495, 565, 4, 2, 51, 2289, 203, 3268, 216, 6, 3, 64, 494, 7, 2431, 2, 287, 469, 126, 88, 186, 2, 36, 226, 767, 30, 204, 115, 55, 3, 6, 1132, 1091, 1478, 66, 3042, 66, 3318, 708, 271, 1220, 6096, 545, 2356, 17, 372, 3197, 8385, 4040, 721, 3, 66, 386, 1, 22, 221, 1, 569, 203, 852, 64, 991, 63, 536]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique tokens')\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "\n",
    "print(\"Line 1: \", reviews[1])\n",
    "print(\"\\nCoded: \", sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5abd7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data =  (20491, 300)\n",
      "Shape of ratings =  (20491,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = pad_sequences(sequences, maxlen = max_review_length)\n",
    "\n",
    "ratings_array = []\n",
    "for i in ratings:\n",
    "    if ratings[i] ==1:\n",
    "        ratings_array.append([1,0,0,0,0])\n",
    "    if ratings[i] ==2:\n",
    "        ratings_array.append([0,1,0,0,0])\n",
    "    if ratings[i] ==3:\n",
    "        ratings_array.append([0,0,1,0,0])\n",
    "    if ratings[i] ==4:\n",
    "        ratings_array.append([0,0,0,1,0])\n",
    "    if ratings[i] ==5:\n",
    "        ratings_array.append([0,0,0,0,1])\n",
    "        \n",
    "print('Shape of data = ', data.shape)\n",
    "print('Shape of ratings = ', ratings.shape)\n",
    "\n",
    "#print(ratings)\n",
    "ratings_array = np.array(ratings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3cae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "\n",
    "np.random.seed(9)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "data = data[indices]\n",
    "ratings_array = ratings_array[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = ratings_array[:training_samples]\n",
    "\n",
    "x_val = data[training_samples:training_samples+validation_samples]\n",
    "y_val = ratings_array[training_samples:training_samples+validation_samples]\n",
    "\n",
    "x_test = data[training_samples+validation_samples: training_samples+validation_samples+test_samples]\n",
    "y_test = ratings_array[training_samples+validation_samples: training_samples+validation_samples+test_samples]\n",
    "\n",
    "#print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ad3ecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of words in glove embeddings = 400000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "glove_dir = 'glove'\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding = 'utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('no of words in glove embeddings =', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7072b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:hotel\t--> [ 0.43044001 -0.71715999  0.13989     0.59311002 -0.16727     0.56128001]\n",
      "2:room\t--> [-0.024843    0.47766     0.32437    -0.054239   -0.47622001  1.10430002]\n",
      "3:not\t--> [-0.19103999  0.17601     0.36919999 -0.50322998 -0.47560999  0.15798   ]\n",
      "4:great\t--> [-0.013786    0.38216001  0.53236002  0.15261    -0.29694    -0.20558   ]\n",
      "5:n't\t--> [ 0.15730999  0.3953      0.63586003 -1.09749997 -0.95767999 -0.013841  ]\n",
      "6:good\t--> [-0.030769    0.11993     0.53908998 -0.43696001 -0.73936999 -0.15345   ]\n",
      "7:staff\t--> [-0.61250001 -0.29506999 -0.28917    -0.36431    -0.39695001  0.097624  ]\n",
      "8:stay\t--> [-0.41615999 -0.26538     0.21720999 -0.26014999 -0.18043999  0.38745001]\n",
      "9:did\t--> [ 0.30449    -0.19628     0.20225    -0.61686999 -0.68484002 -0.11887   ]\n",
      "10:just\t--> [ 0.075026    0.39324999  0.90314001 -0.30451    -0.32767999  0.59630001]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i<max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "for word,i in word_index.items():\n",
    "    if i>10: break\n",
    "    print(f'{i}:{word}\\t--> { embedding_matrix[i, 0:6]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f92f6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 100)          1000000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               29312     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,029,957\n",
      "Trainable params: 29,957\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "network_g = Sequential()\n",
    "network_g.add(Embedding(max_words, embedding_dim, input_length =max_review_length, weights = [embedding_matrix], trainable = False))\n",
    "network_g.add(SimpleRNN(128))\n",
    "network_g.add(Dense(5, activation='softmax'))\n",
    "network_g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3642799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 37s 113ms/step - loss: 0.5481 - acc: 0.8376 - val_loss: 0.4432 - val_acc: 0.8490\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 39s 125ms/step - loss: 0.4467 - acc: 0.8426 - val_loss: 0.4562 - val_acc: 0.8518\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 39s 126ms/step - loss: 0.4051 - acc: 0.8563 - val_loss: 0.4376 - val_acc: 0.8394\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.3896 - acc: 0.8608 - val_loss: 0.4368 - val_acc: 0.8460\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 39s 124ms/step - loss: 0.3209 - acc: 0.8865 - val_loss: 0.4606 - val_acc: 0.8530\n"
     ]
    }
   ],
   "source": [
    "network_g.layers[0].trainable = True\n",
    "\n",
    "network_g.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['acc'])\n",
    "\n",
    "hist_g = network_g.fit(x_train, y_train, epochs = 5, batch_size = 32, validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee55d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 14s 29ms/step - loss: 0.4759 - acc: 0.8487\n"
     ]
    }
   ],
   "source": [
    "test = network_g.evaluate(x_test, y_test, steps = 500, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643d86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49e132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
